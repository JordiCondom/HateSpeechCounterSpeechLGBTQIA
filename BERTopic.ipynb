{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a29d1a-13a3-4312-98fd-dd217d756b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import hdbscan\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from umap import UMAP\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# BERTopic Imports\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, PartOfSpeech\n",
    "from bertopic.vectorizers import CountVectorizer\n",
    "\n",
    "# NLTK Data Downloads\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0605a47-86dc-48ac-b458-35c5586710d5",
   "metadata": {},
   "source": [
    "# General BERTopic implementation\n",
    "Parameters of dimensionality reductino, clustering, and others can be finetuned using a coherence metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd3397-58b5-41c3-be77-5f0a77a31b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_speech_docs = filtered_data['clean_text'].tolist()\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "embeddings = embedding_model.encode(hate_speech_docs)\n",
    "\n",
    "default_stop_words = vectorizer.get_stop_words()\n",
    "removed_stop_words = {}#Define a set of stopwords you want to consdier not stopwords. In our case we included pronouns\n",
    "custom_stop_words = list(default_stop_words.difference(removed_stop_words))\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=custom_stop_words, ngram_range=(1, 1))\n",
    "\n",
    "# Define the different representation models as desired\n",
    "representation_model = {\n",
    "    \"KeyBERT\": KeyBERTInspired(),\n",
    "    \"Aspect1\": PartOfSpeech(\"en_core_web_trf\"),\n",
    "    \"Aspect2\": [KeyBERTInspired(top_n_words=10), MaximalMarginalRelevance(diversity=.8)],\n",
    "}\n",
    "\n",
    "# Define the hdbscan and umap models \n",
    "hdbscan_model = #provide your hdbscan model\n",
    "umap_model = #provide your umap model\n",
    "\n",
    "# Initialize the BERTopic model\n",
    "topic_model = BERTopic(\n",
    "    language=\"english\",\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    representation_model=representation_model,\n",
    "    top_n_words=10,\n",
    "    verbose=True,\n",
    "    calculate_probabilities=True,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    umap_model=umap_model\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(hate_speech_docs, embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
